# Финальный проект в рамках 2 семестра Deep Learning School, весна 2025

**Тема:**  Оценка релевантности организаций запросам на Яндекс.Картах с помощью LLM-агента

**Описание:** Необходимо создать LLM-агента, который будет оценивать релевантность организаций на Яндекс.Картах широким запросам (например, ""ресторан с верандой"" или ""романтичный джаз-бар""). LLM-агент должен будет самостоятельно находить необходимые данные для принятия правильного решения.
Данные представлены компанией Яндекс и являются результатами асессорской разметки релевантности. Чтобы не тратить слишком много денег на походы в платные API, выборка для скоринга будет состоять всего из 500 пар (запрос, организация). Обучающая выборка для бейзлайна будет размера 20000, но ее использование для агентской истории не предполагается (разве что в формате few-shot).

**План:**
1. Написать сильный бейзлайн
2. Разобраться с фреймворком для реализации LLM-агентов
3. Реализовать первую версию агента, где система атоматически принимает решение об использовании поисковика
4. Поработать над улучшением качества

**Содержание репозитория:**
1. `maps-baseline-dls.ipynb` - ноутбук с обучением и инференсом бейзлайна (трансформер + полносвязные слои)
2. `agent-v0-dls.ipynb` - ноутбук с созданием и инференсом нулевой версии агента (можно отнести к сильному бейзлайну, агент не принимает решение о поиске информации в интернете)
3. `agent_v1_dls.ipynb` - ноутбук с созданием и инференсом первой версии агента
4. `agent_v2_dls.ipynb` - ноутбук с созданием и инференсом второй версии агента (в гите может не отображаться, можно посмотреть по ссылке `https://colab.research.google.com/drive/1-RaHaWSZcDoYrfaUVPh3YyHh5NaC0en4?usp=sharing`)

Дополнительные файлы в датасете на kaggle: `https://www.kaggle.com/datasets/kislovka/dls-project-ds/data`

В нем можно найти:
1. `baseline_maps.pth` - веса основной версии бейзлайна (на которой было решено остановиться)
2. `light_baseline_maps.pth` - веса дополнительной версии бейзлайна (модель с меньшим количеством весов)
3. `train_maps_big.csv` - датасет для обучения основной версии бейзлайна
4. `eval_maps_big.csv` - датасет для тестирования основной версии бейзлайна
5. `train_maps.csv` - датасет для обучения дополнительной версии бейзлайна и валидации агентов
6. `eval_maps.csv` - датасет для тестирования дополнительной версии бейзлайна и агентов
7. `for_rag.csv` - набор примеров для RAG (для второй версии агента)
8. `eval_gemini_exp1_exp2.csv` - здесь есть тестовые примеры и ответы нулевой версии агента, первой и бейзлайна
9. `eval_gemini_final.csv` - здесь есть тестовые примеры и ответы нулевой версии агента, первой, бейзлайна и второй версии

**Особенности данного решения кейса проекта:** 
1. Использование не самых мощных моделей (`gemini-2.0-flash`, `gemini-2.5-flash`, `gemini-2.5-pro`), но без вложения каких-либо средств (удобное API и хорошее количество бесплатных запросов в день)
2. Упор в последней версии агента на моделирование сложного взаимодействия между сущностями системы (2 агента, RAG, поиск и дополнительные инструменты), а не на промпт-инжиниринг. Интуиция последнего пункта в том, что оценить релевантность одним из двух чисел может быть сложно и субъективно, поэтому, специализируя промптом агента на строгих правилах оценки, мы можем получить узко мыслящего агента, который покажет меньший скор (как это вышло в первой версии). Агент второй версии может использовать логику оценки их примеров RAG (подробнее об этом в `agent_v2_dls.ipynb`). Но это не значит, что такой подход исключает модернизацию промпта

**Полученные результаты (accuracy):**
- бейзлайн: `0.71` (нулевая версия агента: `0.764`)
- первая версия агента: `0.684`
- вторая версия агента: `0.78` (после трюка: `0.84`, подробнее в ноутбуке)

**Перспективы:**
В теории, добиться скора выше `0.85` можно системой агента второй версии, если:
1. Убрать тул `get_hint_tool` (его агент почти не использовал; скор бейзлайна слишком низок для опоры)
2. Убрать RAG или усовершенствовать его (переразметить трейн, добавить более подробное объяснение, выдавать больше примеров, вызывать вспомогательным агентом - недорогой и быстрой моделью). Но рациональнее и быстрее первый вариант
3. Взять более продвинутую LLM (например, GPT 4 или DeepSeek R1)
4. Оставить вспомогательного агента, он хорошо суммаризировал результаты поиска, чтобы промпт основного агента сильно не засорялся
5. Очевидно, поработать над промптом
6. Добавить несколько тулов поиска, потому что Tavily часто не выдавал нужный результат
7. Дополнительно переразметить тестовый датасет, чтобы убрать оставшиеся явные несостыковки
Упор лучше сделать на 3 и 5 пункты. Данная задача, вероятно, не требует хитрого пайплайна




 
